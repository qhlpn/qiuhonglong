

### 系统初始化

#### 内核子系统

+ 系统调用子系统：操作系统功能调用的统一入口
+ 进程管理子系统：对执行的程序进行生命周期和资源管理
+ 内存管理子系统：对操作系统的内存进行分配、回收、隔离
+ 文件子系统：对文件进行管理
+ 设备子系统：对输入输出设备进行管理
+ 网络子系统：网络协议栈和收发网络包

<img src="pictures/21a9afd64b05cf1ffc87b74515d1d4f5.jpeg" alt="img" style="zoom: 25%;" />



#### x86架构

<img src="pictures/fa6c2b6166d02ac37637d7da4e4b579b.jpeg" alt="img" style="zoom: 33%;" />

+ 对于一个计算机来讲，最核心的就是**CPU**（Central Processing Unit，中央处理器）。这是这台计算机的大脑，所有的设备都围绕它展开。
+ CPU和其他设备连接，要靠一种叫作**总线**（Bus）的东西，其实就是主板上密密麻麻的集成电路，这些东西组成了CPU和其他设备的高速通道。
+ 在这些设备中，最重要的是**内存**（Memory）。因为单靠CPU是没办法完成计算任务的，很多复杂的计算任务都需要将中间结果保存下来，然后基于中间结果进行进一步的计算。CPU本身没办法保存这么多中间结果，这就要依赖内存了。
+ 当然总线上还有一些其他设备，例如显卡会连接显示器、磁盘控制器会连接硬盘、USB控制器会连接键盘和鼠标等等。

<img src="pictures/3afda18fc38e7e53604e9ebf9cb42023.jpeg" alt="img" style="zoom: 25%;" />

CPU和内存是完成计算任务的核心组件，**CPU和内存是如何配合工作的？**

CPU包括三个部分，运算单元、数据单元和控制单元。

+ **运算单元**只管算，例如做加法、做位移等等。但是，它不知道应该算哪些数据，运算结果应该放在哪里。
+ 运算单元计算的数据如果每次都要经过总线，到内存里面现拿，这样就太慢了，所以就有了**数据单元**。数据单元包括CPU内部的缓存和寄存器组，空间很小，但是速度飞快，可以暂时存放数据和运算结果。
+ 有了放数据的地方，也有了算的地方，还需要有个指挥到底做什么运算的地方，这就是**控制单元**。CPU的控制单元里面，有一个**指令指针寄存器**，它里面存放的是下一条指令在内存中的地址。控制单元会不停地将代码段的指令拿进来，先放入指令寄存器。当前的指令分两部分，一部分是做什么操作，例如是加法还是位移；一部分是操作哪些数据。要执行这条指令，就要把第一部分交给运算单元，第二部分交给数据单元。

CPU和内存来来回回传数据，靠的都是总线。总线上主要有两类数据，一个是地址数据，也就是我想拿内存中哪个位置的数据，这类总线叫**地址总线**（Address Bus）；另一类是真正的数据，这类总线叫**数据总线**（Data Bus）。

<img src="pictures/e2e92f2239fe9b4c024d300046536d76.jpeg" alt="img" style="zoom: 25%;" />

那CPU中总线的位数有没有个标准呢？如果没有标准，那操作系统作为软件就很难办了，因为软件层没办法实现通用的运算逻辑。好在历史将**x86**平台推到了**开放、统一、兼容**的位置。

+ 数据单元：为了暂存数据，8086处理器内部有8个16位的通用寄存器，也就是刚才说的CPU内部的数据单元，分别是AX、BX、CX、DX、SP、BP、SI、DI。这些寄存器主要用于在计算过程中暂存数据。

+ 控制单元：IP寄存器就是指令指针寄存器（Instruction Pointer Register)，指向代码段中下一条指令的位置。如果需要切换进程呢？每个进程都分代码段和数据段，为了指向不同进程的地址空间，有四个16位的段寄存器，分别是CS、DS、SS、ES。
  + CS就是代码段寄存器（Code Segment Register），通过它可以找到代码在内存中的位置；
  + DS是数据段的寄存器，通过它可以找到数据在内存中的位置。
  + SS是栈寄存器（Stack Register）。栈是程序运行中一个特殊的数据结构，数据的存取只能从一端进行，秉承后进先出的原则，push就是入栈，pop就是出栈。
  + ES是附加段寄存器

段寄存器的工作模式

+ 实模式：只能寻址1M，每个段最多64K（只使用了20位地址总线）
+ 保护模式：打开Gate A20，也就是第21根地址线的控制线，能够寻址4G。



#### 从bios到bootloader

<img src="pictures/0a29c1d3e1a53b2523d2dcab3a59886b.jpeg" alt="img" style="zoom:25%;" />

+ **BIOS**：在主板上，有一个东西叫**ROM**（Read Only Memory，只读存储器），上面早就固化了一些初始化的程序，也就是**BIOS**（Basic Input and Output System，基本输入输出系统）。在x86系统中，将1M空间最上面的0xF0000到0xFFFFF这64K映射给ROM，也就是说，到这部分地址访问的时候，会访问ROM。当电脑刚加电的时候，会做一些重置的工作，将CS设置为0xFFFF，将IP设置为0x0000，所以第一条指令就会指向0xFFFF0，正是在ROM的范围内。在这里，有一个JMP命令会跳到ROM中做初始化工作的代码，于是，BIOS开始进行初始化的工作。
+ **bootloader**：操作系统在哪儿呢？一般都会在安装在硬盘上，在BIOS的界面上。你会看到一个启动盘的选项。启动盘有什么特点呢？它一般在第一个扇区，占512字节，而且以0xAA55结束。这个扇区通常称为**MBR**（Master Boot Record，主引导记录/扇区），执行**Grub2**配置的boot.img。由于512个字节实在有限，boot.img做不了太多的事情。它能做的最重要的一个事情就是加载**Grub2**的另一个镜像core.img，包含了diskboot.img、lzma_decompress.img（实模式切换到保护模式）、kernel.img



#### 内核初始化

内核的启动从入口函数start_kernel()开始。在init/main.c文件中，start_kernel相当于内核的main函数。打开这个函数，你会发现，里面是各种各样初始化函数XXXX_init。

<img src="pictures/cdfc33db2fe1e07b6acf8faa3959cb01.jpeg" alt="img" style="zoom:25%;" />

+ 在操作系统里面，先要有个创始进程，有一行指令set_task_stack_end_magic(&init_task)。这里面有一个参数init_task，它的定义是struct task_struct init_task = **INIT_TASK(init_task)**。它是系统创建的第一个进程，我们称为**0号进程**。这是唯一一个没有通过fork或者kernel_thread产生的进程，是进程列表的第一个。
+ **trap_init()**，里面设置了很多**中断门**（Interrupt Gate），用于处理各种中断。其中有一个set_system_intr_gate(IA32_SYSCALL_VECTOR, entry_INT80_32)，这是系统调用的中断门。系统调用也是通过发送中断的方式进行的。
+ **mm_init()** 就是用来初始化内存管理模块
+ **sched_init()** 就是用于初始化调度模块。
+ 最后，start_kernel()调用的是 **rest_init()**，用来做其他方面的初始化，这里面做了好多的工作。
  + rest_init的第一大工作是，用kernel_thread(kernel_init, NULL, CLONE_FS)创建第二个进程，这个是**1号进程**。1号进程对于操作系统来讲，有“划时代”的意义。因为它将运行一个**用户态进程**。运行 **ramdisk（根文件系统）**的 **/init**，成为所有用户态进程的祖先。
  + rest_init第二大事情就是创建第三个进程，就是2号进程，负责所有**内核态**的线程的调度和管理，是内核态所有线程运行的祖先。

<img src="pictures/d2fce8af88dd278670395ce1ca6d4d14.jpg" alt="img" style="zoom:33%;" />



#### 系统调用过程

Linux提供了**glibc**中间层。它更熟悉系统调用的细节，并且可以封装成更加友好的接口。

用户态进程里面调用open函数，调用的是glibc里面的open函数，进而调用内核的open函数。

<img src="pictures/868db3f559ad08659ddc74db07a9a0a5.jpg" alt="img" style="zoom:25%;" />

### 进程管理

#### 创建进程

1. 预处理：展开宏定义      gcc -E hello.c -o hello.i
2. 编译：生成汇编文件      gcc -S hello.c -o hello.s
3. 汇编：将汇编指令转为机器指令，生成目标文件       gcc -c hello.c -o hello.o
4. 链接：整合依赖的库，生成可执行文件         gcc hello.c

<img src="pictures/dbd8785da6c3ce3fe1abb7bb5934b7a9.jpeg" alt="img" style="zoom:25%;" />

**创建进程：从代码到二进制到运行时**

首先通过图右边的文件编译过程，生成so文件和可执行文件，放在硬盘上。

下图左边的用户态的进程A执行fork，创建进程B，在进程B的处理逻辑中，执行exec系列系统调用。

系统调用会通过load_elf_binary方法，将刚才生成的可执行文件，加载到进程B的内存中执行。

**fork函数：**

执行完毕后，如果创建新进程成功，则出现两个进程。

一个是子进程，一个是父进程，各自执行各自的代码分支。

在子进程中，fork函数返回0，在父进程中，fork返回新创建子进程的进程ID。



#### 创建线程

<img src="pictures/e38c28b0972581d009ef16f1ebdee2bd.jpg" alt="img" style="zoom: 33%;" />





#### 数据结构

<img src="pictures/image-20220108170526704.png" alt="image-20220108170526704" style="zoom: 33%;" />

+ **任务ID**

  ```c++
  pid_t pid;
  pid_t tgid;
  struct task_struct *group_leader; 
  ```

  进程和线程在内核统一视为任务，如何区分？通过判断 pid == tgid 。场景：展示进程、给进程下发指令

  pid:processId、tgid:threadgroupId

  任何一个进程，如果只有主线程，那pid是自己，tgid是自己，group_leader指向的还是自己。

  如果一个进程创建了其他线程，线程有自己的pid，tgid就是进程的主线程的pid，group_leader指向的就是进程的主线程。

  

+ **任务状态**

  <img src="pictures/e2fa348c67ce41ef730048ff9ca4c988.jpeg" alt="img" style="zoom: 33%;" />

  + **TASK_RUNNING**：准备运行，看CPU时间片调度
  + **TASK_INTERRUPTIBLE**：可中断的睡眠状态【睡眠：如等待IO】
  + **TASK_UNINTERRUPTIBLE**：不可中断的睡眠状态（无法被信号唤醒，只能等IO完成，或者重启电脑）
  + **TASK_KILLABLE**：相比TASK_INTERRUPTIBLE，只可响应KILL信号
  + **EXIT_ZOMBIE**：僵尸进程（父进程还没使用wait()等系统调用来获知它的终止信息）
  + **EXIT_DEAD**：进程的最终状态

  

+ **信号处理**

  ``` c++
  /* Signal handlers: */
  struct signal_struct		*signal;
  struct sighand_struct		*sighand;
  sigset_t			blocked;
  sigset_t			real_blocked;
  sigset_t			saved_sigmask;
  struct sigpending		pending;
  unsigned long			sas_ss_sp;
  size_t				sas_ss_size;
  unsigned int			sas_ss_flags;
  ```

  这里定义了哪些信号被阻塞暂不处理（blocked），哪些信号尚等待处理（pending），哪些信号正在通过信号处理函数进行处理（sighand）。处理的结果可以是忽略，可以是结束进程等等。

  

+ **统计信息**

  ``` c++
  u64				utime;//用户态消耗的CPU时间
  u64				stime;//内核态消耗的CPU时间
  unsigned long	nvcsw;//自愿(voluntary)上下文切换计数
  unsigned long	nivcsw;//非自愿(involuntary)上下文切换计数
  u64				start_time;//进程启动时间，不包含睡眠时间
  u64				real_start_time;//进程启动时间，包含睡眠时间
  ```

+ **进程亲缘关系**

  ``` c++
  struct task_struct __rcu *real_parent; /* real parent process */
  struct task_struct __rcu *parent; /* recipient of SIGCHLD, wait4() reports */
  struct list_head children;      /* list of my children */
  struct list_head sibling;       /* linkage in my parent's children list */
  ```

  从创建进程可以看出，任何一个进程都有父进程。

  整个进程其实就是一棵进程树。而拥有同一父进程的所有进程都具有兄弟关系。

  parent 指向其父进程。当它终止时，必须向它的父进程发送信号。

  children 表示链表的头部。链表中的所有元素都是它的子进程。

  sibling 用于把当前进程插入到兄弟链表中。

  

+ **进程权限** 

  用户运行进程，进程权限由对应的用户和用户组权限决定，RWX .

  

+ **进程调度**

  进程的状态切换涉及到进程调度。

  

+ **内存管理**

  ``` c++
  struct mm_struct                *mm;
  struct mm_struct                *active_mm;
  ```

  每个进程都有自己独立的虚拟内存空间，这需要有一个数据结构来表示，就是mm_struct。

  

+ **文件与文件系统**

  ``` c++
  struct fs_struct                *fs;      /* Filesystem information: */
  struct files_struct             *files;   /* Open file information: */    
  ```

  每个进程有一个文件系统的数据结构，还有一个打开文件的数据结构。



#### 进程调度

<img src="pictures/10381dbafe0f78d80beb87560a9506af.jpeg" alt="img" style="zoom:33%;" />

每个CPU上有对应的队列，CFS的队列是一棵红黑树。

树的每个节点都是一个sched_entity，每个sched_entity都属于一个task_struct。

task_struct里面有指针指向这个进程属于哪个调度类。



+ **调度策略**

  + **实时进程**：（优先级 0～99【数字越小级别越高】）

    + **SCHED_FIFO**：相同优先级下先来先服务，高优先级可抢占低优先级
    + **SCHED_RR**：相同优先级下时间片轮询，高优先级可抢占低优先级
    + **SCHED_DEADLINE**：按照任务的ddl进行调度，选择离ddl最近的任务执行

  + **普通进程**：（优先级 100~139）

    **SCHED_CFS**：Completely Fair Scheduling 完全公平调度

    首先，你需要记录下进程的运行时间。

    CPU会提供一个时钟，过一段时间就触发一个时钟中断。就像咱们的表滴答一下，这个我们叫Tick。

    CFS会为每一个进程安排一个虚拟运行时间vruntime。

    如果一个进程在运行，随着时间的增长，也就是一个个tick的到来，进程的vruntime将不断增大。

    没有得到执行的进程vruntime不变。

    显然，那些vruntime少的，原来受到了不公平的对待，需要给它补上，所以会优先运行这样的进程。

    其次，如何给优先级高的进程多分时间呢？加权重系数，按比例！

    总vruntime不变，每到来一个tick，高优先级进程的vruntime的增长权重低，低优先级的高。

    

+ **调度队列**：红黑树（给vruntime排序）

  每个CPU都有自己的 struct rq 结构，其用于描述在此CPU上所运行的所有进程。

  包括一个实时进程队列rt_rq和一个CFS运行队列cfs_rq。



+ **调度类**

  当CPU需要找下个任务执行时，会按照优先级依次调用调度类，不同的调度类操作不同的队列。

  rt_sched_class先被调用，它会在rt_rq上找下一个任务。

  只有找不到的时候，才轮到fair_sched_class被调用，它会在cfs_rq上找下一个任务。

  这样保证了实时任务的优先级永远大于普通任务。



### 内存管理



- 第一，虚拟内存的管理，将虚拟内存分成大小相等的页；
- 第二，物理内存的管理，将物理内存分成大小相等的页；
- 第三，内存映射，将虚拟内存也和物理内存也映射起来，并且在内存紧张的时候可以换出到硬盘中。



#### 物理内存

<img src="pictures/8f158f58dda94ec04b26200073e15449.jpeg" alt="img" style="zoom: 33%;" />

+ SMP（对称多处理器）：所有的内存条组成一大片内存，所有的CPU访问内存都要过总线，而且距离都是一样的（总线见x86图）
+ NUMA（非统一内存访问）：内存不是一整块，每个CPU都有自己的本地内存，CPU访问本地内存不用过总线，因而速度要快很多。每个CPU和内存在一起，称为一个**NUMA节点**。但是，在本地内存不足的情况下，每个CPU都可以去另外的NUMA节点申请内存，这个时候访问延时就会比较长。



**物理内存的组织形式**：

+ 如果有多个CPU，那就有多个NUMA **节点**。每个节点用struct pglist_data表示，放在一个数组里面。
+ 每个节点分为多个 **区域**，每个区域用struct zone表示，也放在一个数组里面
+ 每个区域分为多个 **页**。空闲页放在struct free_area里面，使用伙伴系统进行管理和分配，每一页用struct page表示

<img src="pictures/3fa8123990e5ae2c86859f70a8351f4f.jpeg" alt="img" style="zoom: 25%;" />





#### 虚拟内存

CPU 32位 指 地址总线宽度 32 位 （A0-A31），意味着 CPU 最大的寻址范围是 2^32 = 4G（区别于4GB）

​                       数据总线宽度 32 位（D0-D31），一次能读写的最大字节数是 32 Bit (4 Byte)

每个进程有虚拟地址空间 4GB （4G x 1Byte 仅是归一方便计算，否则是 4G x 4Byte）

虚拟地址空间分为 **内核空间** 和 **用户空间**：进程在用户态时，只能访问用户空间内存，只有进入内核态后，才可以访问内核空间的内存

虽然每个进程都各自有独立的虚拟内存，但是 **每个虚拟内存中的内核地址，其实关联的都是相同的物理内存**

<img src="pictures/image-20220127112330518.png" alt="image-20220127112330518" style="zoom:67%;" />



#### 分段

段则是信息的逻辑单位，人为划分为：

+ **ELF** ：Text Segment：存放二进制可执行代码的位置。Data Segment：存放静态常量。BSS Segment：存放未初始化的静态变量
+ **堆**（Heap）**段**：动态分配内存的区域
+ **Memory Mapping Segment**（mmap内存映射区）：用来把文件内容映射到虚拟内存，比如映射二进制的执行文件依赖的某个动态链接库。
+ **栈**（Stack）**地址段**：函数栈所在位置

分段可以做权限审核，例如用户态DPL是3，内核态DPL是0。当用户态试图访问内核态的时候，会因为权限不足而报错。

<img src="pictures/7c82068d2d6bdb601084a07569ac8b04.jpg" alt="img" style="zoom: 33%;" />

#### 分页

页是信息的物理单位，内存换入换出的粒度更小（整个段的粒度大）

4G 32位 虚拟地址范围 可分为两部分：页号（20Bit） + 页内偏移（12Bit） 

<img src="pictures/image-20220127111653855.png" alt="image-20220127111653855" style="zoom: 67%;" />

对于单页表的实现方式，在 32 位 和 页大小 4KB（2^12 * 1Byte） 的环境下，一个进程的页表需要装下 2^20 个页表项，每个 页表项 需要 4 Byte 来存储，则整个 4GB 空间的映射需要有 4MB 的内存来存储页表。100个进程...

<img src="pictures/image-20220127111813093.png" alt="image-20220127111813093" style="zoom: 80%;" />

分了二级表，映射 4GB 地址空间就需要 4KB 一级页表 （2^10 页表项）+ 4MB 二级页表（2^10 x 2^10 页表项）的内存，内存变大？

**局部性原理**：如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表

单级页表不行？内存中页表职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以页表一定要覆盖全部虚拟地址空间

**TLB**：（Translation Lookaside Buffer）页表缓存、快表 降低地址转换带来的时间复杂度



#### 内存分配

物理内存根据NUMA架构分节点。每个节点里面再分区域。每个区域里面再分页。

物理内存页面通过伙伴系统进行分配。分配的物理页面要变成虚拟地址让上层可以访问，kswapd可以根据物理页面的使用情况对页面进行换入换出。

对于内存申请的需求，可能来自内核态，也可能来自用户态。

+ 内核态

  + kmalloc分配大内存，vmalloc分配不连续物理页时，使用伙伴系统，分配后转换为虚拟地址，访问时需要通过内核页表进行映射
  + kmalloc分配小内存，以及kmem_cache_create/alloc时，则使用slub allocator分配器，将伙伴系统分配出来的大块内存切成小块进行分配

  kmalloc和kmem_cache_create/alloc分配的页部分不会被换出，只有vmalloc分配的部分会被换出，缺页异常调用do_page_fault

+ 用户态

  + mmap，进而调用sys_mmap进行分配
  + malloc，如果分配小的内存，就用sys_brk系统调用；如果分配大的内存，还是用sys_mmap系统调用

  正常情况下，用户态的内存都是可以换出的，缺页异常调用do_page_fault

<img src="pictures/274e22b3f5196a4c68bb6813fb643f9a.png" alt="img" style="zoom: 30%;" />

#### 伙伴系统

+ 背景：分页系统不会产生外部碎片，一个进程占用的内存空间可以是不连续的，并且一个进程的虚拟页面在不需要的时候可以存放在磁盘上。但是当进程需要较大运行内存，频繁地请求和释放不同大小的一组连续页框，必然导致在已分配的块内分散了许多小块的空闲页面，由此带来的问题是，即使**有足够的空闲页面可以满足请求，但要分配一个大块的连续页框可能无法满足请求**。
+ 作用：高效的分配和回收资源，降低外部碎片。
+ 原理：Linux中的内存管理的页大小为4KB。把所有的空闲页分组为11个页块链表，每个块链表分别包含很多个大小的页块，有1、2、4、8、16、32、64、128、256、512和1024个连续页的页块。最大可以申请1024个连续页，对应4MB大小的连续内存。每个页块的第一个页的物理地址是该页块大小的整数倍。
+ 示例：请求一个128个页的页块时，先检查128个页的页块链表是否有空闲块。如果没有，则查256个页的页块链表；如果有空闲块的话，则将256个页的页块分成两份，一份使用，一份插入128个页的页块链表中。如果还是没有，就查512个页的页块链表；如果有的话，就分裂为128、128、256三个页块，一个128的使用，剩余两个插入对应页块链表。

<img src="pictures/2738c0c98d2ed31cbbe1fdcba01142cf.jpeg" alt="img" style="zoom: 33%;" />

### 文件管理

Linux：一切皆文件，文件又可分为：普通文件、目录文件、字符设备文件、块设备文件、套接字文件、链接文件



#### 文件系统: ext4

##### inode/block

+ inode：文件元数据、索引
+ block：磁盘数据块 4K

``` c
struct ext4_inode {
	__le16	i_mode;		/* 读写权限 */
	__le16	i_uid;		/* 用户 */
	__le32	i_size_lo;	/* 大小 */
	__le32	i_atime;	/* 访问文件时间 */
	__le32	i_ctime;	/* 修改inode时间 */
	__le32	i_mtime;	/* 修改文件数据时间 */
	__le32	i_dtime;	/* 删除文件时间 */
	__le16	i_gid;		/* 用户组 */
	__le16	i_links_count;	/* Links count */
	__le32	i_blocks_lo;	/* 块个数 */
	__le32	i_flags;	/* File flags */
......
	__le32	i_block[EXT4_N_BLOCKS];/* 块指针数组 */
	__le32	i_generation;	/* File version (for NFS) */
	__le32	i_file_acl_lo;	/* File ACL */
	__le32	i_size_high;
......
};
```

i_block[EXT4_N_BLOCKS] 索引磁盘数据块的方式：

+ 数组：前12项直接保存了块的位置，大于12的项才开始使用间接块。

  i_block[12]里面放间接块的位置，通过i_block[12]找到间接块后，间接块里面放数据块的位置，通过间接块可以找到数据块。

  对于大文件来讲，我们要多次读取硬盘才能找到相应的块，这样访问速度就会比较慢。

  <img src="pictures/73349c0fab1a92d4e1ae0c684cfe06e2.jpeg" alt="img" style="zoom:25%;" />

+ BTree：降低树的高度，减少读取磁盘次数

  i_block[i]指向的 4K数据块 里，存放着 数据块指针项 Extents（header+N entry）,header 和 entry 大小都是12Byte

  4K 扣除 header 12Byte，还能够存放 340个 Entry，每个Entry指向的 位图数据块 可表示空间 2^{15} * 4K  = 128M，故一层树就能表示42.5GB文件

  <img src="pictures/b8f184696be8d37ad6f2e2a4f12d002a.jpeg" alt="img" style="zoom:33%;" />

##### 位图

由上可知，硬盘上肯定有一系列的inode和block排列起来。

接下来的问题是，如果我要保存一个数据块，或者要保存一个inode，我应该放在硬盘上的哪个位置呢？

难道需要将所有的inode列表和块列表扫描一遍，找个空的地方随便放吗？

当然，这样效率太低了。所以在文件系统里面，我们专门弄了一个块来保存inode的位图。

在这4k里面，每一位对应一个inode。如果是1，表示这个inode已经被用了；如果是0，则表示没被用。

同样，我们也弄了一个块保存block的位图。



##### 文件系统格式

**一个块的位图 + 一系列的块** 的结构只能表示 128M，现在很多文件都比这个大，暂且把这结构称作一个块组

这样一个个块组，就基本构成了我们整个文件系统的结构。因为块组有多个，块组描述符也同样组成一个列表，我们把这些称为**块组描述符表**。

当然，我们还需要有一个数据结构，对整个文件系统的情况进行描述，这个就是**超级块**

默认情况下，超级块和块组描述符表都有副本保存在每一个块组里面。

对于整个文件系统，别忘了咱们讲系统启动的时候说的，如果是一个启动盘，需要预留一块区域作为引导区，所以第一个块组的前面要留1K，用于启动引导区。

最终，整个文件系统格式就是下面这个样子。

<img src="pictures/e3718f0af6a2523a43606a0c4003631b.jpeg" alt="img" style="zoom:33%;" />



##### 目录存储格式

目录本身也是个文件，也有inode。inode里面也是指向一些数据块。

和普通文件不同的是，普通文件的块里面保存的是文件数据，而目录文件的块里面保存的是目录里面一项一项的文件信息。

每一项都会保存这个目录的下一级的文件的文件名和对应的inode

**目录（文件名 + inode指针）>  文件inode  >  磁盘数据块**

``` c
struct ext4_dir_entry {
	__le32	inode;			/* Inode number */
	__le16	rec_len;		/* Directory entry length */
	__u8	name_len;		/* Name length */
	__u8	file_type;
	char	name[EXT4_NAME_LEN];	/* File name */
};
```



##### 软链接/硬链接

+ 硬链接：A 的目录项中的 inode 指针与 B 的目录项中的 inode 指针相同，即同个 inode 节点对应两个不同的文件名。删除 B 不影响 A。当 inode 节点上的链接数为0时，inode 节点和对应的数据块被回收。
+ 软链接：A 的目录项中的 inode 指针与 B 的目录项中的 inode 指针不相同，A 和 B 指向的是两个不同的 inode，继而指向两块不同的数据块。但是 A 的数据块中存放的只是 B 的目录项路径。删除 B 影响 A 找到文件数据。

<img src="pictures/45a6cfdd9d45e30dc2f38f0d2572be7b.jpeg" alt="img" style="zoom: 25%;" />



#### 虚拟文件系统

<img src="pictures/3c506edf93b15341da3db658e9970773.jpg" alt="img" style="zoom: 33%;" />



- 在应用层，进程在进行文件读写操作时，可通过系统调用如sys_open、sys_read、sys_write等。

- 在内核，每个进程都需要为打开的文件，维护一定的数据结构。

- 在内核，整个系统打开的文件，也需要维护一定的数据结构。

- Linux可以支持不同文件系统。它们的实现各不相同，因此Linux内核向用户空间提供了虚拟文件系统这个统一接口。

  它提供了常见的文件系统对象模型，例如 inode、directory entry、mount 等，

  以及操作这些对象的方法，如 inode operations、directory operations、file operations 等。

- 然后就是对接的是真正的文件系统，比如上述提及的ext4文件系统。

- 为了加快块设备的读写效率，有一个缓存层：

  **对于读，从块设备读取到缓存中，然后从缓存中拷贝到用户态。对于写，从用户态拷贝到缓存，设置缓存页为脏，然后启动一个线程写入块设备**

- 为了读写ext4文件系统，要通过块设备I/O层，也即BIO层。这是文件系统层和块设备驱动的接口。

- 最下层是块设备驱动程序。



#### 系统调用 💥

##### mount

```c
mount_fs(struct file_system_type *type, int flags, const char *name, void *data)
{
	struct dentry *root;
	struct super_block *sb;
	root = type->mount(type, flags, name, data);
	sb = root->d_sb;
......
}
```

这里调用的是ext4_fs_type的mount函数，也就是咱们上面提到的ext4_mount，从文件系统里面读取 **超级块**。

在文件系统的实现中，每个在硬盘上的结构，在内存中也对应相同格式的结构。

当所有的数据结构都读到内存里面，内核就可以通过操作这些数据结构，来操作文件系统了。

![img](pictures/663b3c5903d15fd9ba52f6d049e0dc27.jpeg)

假设根文件系统下面有一个目录home，有另外一个文件系统A挂载在这个目录home下面。

在文件系统A的根目录下面有另外一个文件夹hello，然后有另外一个文件系统B挂在在/home/hello下面。

在文件系统B的根目录下面有另外一个文件夹world，在world下面有个文件夹data。所以我们就有了目录/home/hello/world/data。

为了维护这些关系，操作系统创建了这一系列数据结构。具体可以看上面的图。



##### open/write/read

![img](pictures/8070294bacd74e0ac5ccc5ac88be1bb9.png)

对于每一个进程，打开的文件都有一个文件描述符

在files_struct里面会有文件描述符数组，每个一个文件描述符是这个数组的下标，里面的内容指向一个file结构，表示打开的文件。

file有这个文件对应的inode，最重要的是这个文件对应的操作file_operation。如果操作这个文件，就看这个file_operation里面的定义了。

file有对应的文件路径，进而获取对应的文件系统和文件目录项

对于每一个打开的文件，file都有一个directory dentry目录项，可以指向这个文件对应的 inode、以及 super_block 信息。





### 设备管理

<img src="pictures/80e152fe768e3cb4c84be62ad8d6d07f.jpg" alt="img" style="zoom: 50%;" />



+ 块设备：将信息存储在固定大小的块中，每个块都有自己的地址
+ 字符设备：发送或接受的是字节流，而不用考虑任何块结构，没有办法寻址



#### 设备中断

中断有两种，一种**软中断**，例如代码调用INT指令触发，一种是**硬件中断**，就是硬件通过中断控制器触发的

<img src="pictures/aa9d074d9819f0eb513e11014a5772c0.jpg" alt="img" style="zoom: 33%;" />

**统一流程**：设备驱动程序初始化的时候，要先注册一个该设备的中断处理函数。硬件触发硬中断，**中断是进程切换的时机**。CPU保存上下文，触发do_IRQ函数，这个函数是中断处理的统一入口。在这个函数里面，可以找到设备驱动程序注册的中断处理函数Handler，然后执行它进行中断处理。



#### 文件系统接口

Linux用文件系统接口屏蔽驱动程序的差异

操作设备，都是基于文件系统的接口，首先要统一的是设备名称。所有设备都在**/dev/**文件夹下面创建一个特殊的设备文件。

这个设备特殊文件也有inode，但是它不关联到硬盘或任何其他存储介质上的数据，而是建立了与某个设备驱动程序的连接。

假设是/dev/sdb，这是一个设备文件。这个文件本身和硬盘上的文件系统没有任何关系。这个设备本身也不对应硬盘上的任何一个文件

/dev/sdb其实是在一个特殊的文件系统**devtmpfs**中

当我们将/dev/sdb格式化成一个文件系统ext4的时候，就会将它mount到一个路径下面。例如在/mnt/sdb下面

此时/dev/sdb还是一个设备文件在特殊文件系统devtmpfs中，而/mnt/sdb下面的文件才是在磁盘的ext4文件系统中

```shll
# ls /dev -l
crw------- 1 root root      5,   1 Dec 14 19:53 console
crw-r----- 1 root kmem      1,   1 Dec 14 19:53 mem
crw-rw-rw- 1 root root      1,   3 Dec 14 19:53 null
crw-r----- 1 root kmem      1,   4 Dec 14 19:53 port
crw-rw-rw- 1 root root      1,   8 Dec 14 19:53 random
crw--w---- 1 root tty       4,   0 Dec 14 19:53 tty0
crw--w---- 1 root tty       4,   1 Dec 14 19:53 tty1
crw-rw-rw- 1 root root      1,   9 Dec 14 19:53 urandom
brw-rw---- 1 root disk    253,   0 Dec 31 19:18 vda
brw-rw---- 1 root disk    253,   1 Dec 31 19:19 vda1
brw-rw---- 1 root disk    253,  16 Dec 14 19:53 vdb
brw-rw---- 1 root disk    253,  32 Jan  2 11:24 vdc
crw-rw-rw- 1 root root      1,   5 Dec 14 19:53 zero
```

首先是第一位字符。如果是字符设备文件，则以c开头，如果是块设备文件，则以b开头。

其次是这里面的两个号，一个是主设备号，一个是次设备号。主设备号**定位设备驱动程序**，次设备号作为参数传给启动程序，**选择相应的单元**。

有了设备文件，我们就可以使用对于文件的操作命令和API来操作文件了。

例如，使用cat命令，可以读取/dev/random 和/dev/urandom的数据流，可以用od命令转换为十六进制后查看。

``` shell
cat /dev/urandom | od -x
# /dev/random在类UNIX系统中是一个特殊的设备文件，可以用作随机数发生器或伪随机数发生器。
```

有了文件系统接口之后，我们可以像**读写文件**一样操作设备。

但是有些任务只使用读写很难完成，例如检查特定于设备的功能和属性，超出了通用文件系统的限制。

所以，对于设备来讲，还有一种接口称为**ioctl**，表示输入输出控制接口，是用于**配置和修改特定设备属性**的通用接口



#### 设备驱动程序

设备控制器不属于操作系统的一部分，但是**设备驱动程序属于操作系统的一部分**。

操作系统的内核代码可以像调用本地代码一样调用驱动程序的代码，而驱动程序的代码需要发出特殊的面向设备控制器的指令，才能操作设备控制器。

在Linux里面，安装驱动程序，其实就是加载一个内核模块。

我们可以用命令lsmod，查看有没有加载过相应的内核模块。

```shell
# lsmod
Module                  Size  Used by
iptable_filter         12810  1
bridge                146976  1 br_netfilter
vfat                   17461  0
fat                    65950  1 vfat
ext4                  571716  1
cirrus                 24383  1
crct10dif_pclmul       14307  0
crct10dif_common       12595  1 crct10dif_pclmul
```

如果没有安装过相应的驱动，可以通过insmod安装内核模块。内核模块的后缀一般是ko。

```
insmod openvswitch.ko
```

一旦有了驱动，我们就可以通过命令mknod在/dev文件夹下面创建设备文件

```shell
mknod filename type major minor
```

其中filename就是/dev下面的设备名称，type就是c为字符设备，b为块设备，major就是主设备号，minor就是次设备号。一旦执行了这个命令，新创建的设备文件就和上面加载过的驱动关联起来，这个时候就可以通过操作设备文件来操作驱动程序，从而操作设备。

你可能会问，人家Windows都说插上设备后，一旦安装了驱动，就直接在设备列表中出来了，你这里怎么还要人来执行命令创建呀，能不能智能一点？

当然可以，这里就要用到另一个管理设备的文件系统，也就是**/sys**路径下面的**sysfs**文件系统。

```shell
# ls /sys -l
drwxr-xr-x   2 root root 0 Jan 24 18:24 block   # 是系统中当前所有的块设备
drwxr-xr-x  37 root root 0 Jan 24 18:59 bus
drwxr-xr-x  73 root root 0 Jan 14 09:04 class
drwxr-xr-x   4 root root 0 Jan 14 09:04 dev      # 目录下一个char文件夹，一个block文件夹，分别维护一个按字符设备和块设备的主次号码(major:minor)链接到真实的设备(/sys/devices下)的符号链接文件；
drwxr-xr-x  65 root root 0 Jan  9 11:45 devices  # 是内核对系统中所有设备的分层次的表示；
drwxr-xr-x   7 root root 0 Jan  9 11:45 firmware
drwxr-xr-x   9 root root 0 Jan  9 11:45 fs
drwxr-xr-x   2 root root 0 Jan 28 10:37 hypervisor
drwxr-xr-x  10 root root 0 Jan  9 11:45 kernel
drwxr-xr-x 234 root root 0 Jan 25 11:10 module   # 系统中所有模块的信息
drwxr-xr-x   2 root root 0 Jan 28 10:37 power
```

<img src="pictures/6234738aac8d5897449e1a541d557090.jpg" alt="img" style="zoom: 33%;" />

有了sysfs以后，还需要一个守护进程**udev**。当一个设备新插入系统的时候，内核会检测到这个设备，并创建内核对象kobject 。 这个对象通过sysfs文件系统展现到用户层，同时内核还向**用户空间**发送一个**热插拔**消息。udevd会监听这些消息，在/dev中创建对应的文件。



#### 字符设备

+ **insmod**：
  + 要使用一个字符设备，我们首先要把写好的内核模块，通过insmod加载进内核
  + 在字符设备驱动的内核模块加载的时候，最重要的一件事情就是，注册Linux主机连接的字符设备，分配一个struct cdev结构，将主设备号和次设备号生成一个dev_t的整数，然后将这个整数dev_t和cdev关联起来，将cdev的ops成员变量指向这个模块声明的file_operations。
  + 然后，cdev_add会将每个字符设备添加到内核中一个叫作struct kobj_map *cdev_map的结构，来统一管理所有字符设备。
+ **mknode /dev/xxx**
  + 内核模块加载完毕后，接下来通过mknod在/dev下面创建一个设备文件，这也才能通过文件系统的接口，对这个设备进行操作
  + 这个文件在特殊的devtmpfs文件系统上，有相应的dentry和inode。inode里有设备号。通过它可以在cdev_map中找到设备驱动程序
+ **open / write / read**：通过文件系统操作，进操作字符设备

<img src="pictures/2e29767e84b299324ea7fc524a3dcee6.jpeg" alt="img" style="zoom: 25%;" />





#### 块设备

对于磁盘/dev/sda，我们既可以把它整个格式化成一个文件系统，也可以把它分成多个分区/dev/sda1、 /dev/sda2，然后把每个分区格式化成不同的文件系统

如果我们访问某个分区设备文件/dev/sda2，我们应该能知道它是哪个磁盘设备，如果我们访问整个磁盘设备文件/dev/sda，我们也应该能知道它分了几个区域

+ **gendisk**：用来描述整个设备的，因而上面的例子中，gendisk只有一个实例，指向/dev/sda
  + major是主设备号，first_minor表示第一个分区的从设备号，minors表示分区的数目
  + struct disk_part_tbl结构里是一个struct hd_struct的数组，用于表示各个分区。
  + struct block_device_operations fops指向对于这个块设备的各种操作。
+ **hd_struct**：来表示某个分区的，在上面的例子中，有两个hd_struct的实例，分别指向/dev/sda1、 /dev/sda2
  + 比较重要的成员变量保存了如下的信息：从磁盘的哪个扇区开始，到哪个扇区结束。
+ **block_device**：既可以表示整个块设备，也可以表示某个分区，所以对于上面的例子，block_device有三个实例，分别指向/dev/sda1、/dev/sda2、/dev/sda。
  + bd_disk 指向的gendisk就是整个块设备
  + bd_part指向的某个分区的hd_struct
  + bd_contains指向的是整个块设备的block_device

<img src="pictures/85f4d83e7ebf2aadf7ffcd5fd393b176.png" alt="img" style="zoom: 25%;" />

1. insmod初始化时，所有的块设备被一个map结构管理从dev_t到gendisk的映射；

2. 所有的block_device表示的设备或者分区都在 **bdev伪文件系统** 的inode列表中（why need ？磁盘可以分区）

   bdev 对于内核来说，就是普通的文件系统；所有表示块设备的inode都保存在 伪文件系统 bdev 中，但是这些对用户层不可见

3. mknod创建出来的块设备文件在 **devtemfs文件系统** 里面，特殊inode里面有块设备号；

4. mount一个块设备上的文件系统，调用这个文件系统的mount接口；

5. 通过按照/dev/xxx在文件系统devtmpfs文件系统上搜索到特殊inode，得到块设备号；

6. 根据特殊inode里面的dev_t在bdev文件系统里面找到inode；

7. 根据bdev文件系统上的inode找到对应的block_device，根据dev_t在map中找到gendisk，将两者关联起来；

8. 找到block_device后打开设备，调用和block_device关联的gendisk里面的block_device_operations打开设备；

9. 创建被mount的文件系统的super_block，有了ext4文件系统的super_block之后，接下来对于文件的读写过程，就和文件系统那一章的过程一摸一样了。

<img src="pictures/6290b73283063f99d6eb728c26339620.png" alt="img" style="zoom: 25%;" />





### 网络管理
